{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Step 1:}$ Simulate Rankings of Relevance for E and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0, 0, 0], [0, 0, 0]), ([0, 0, 0], [1, 0, 0]), ([0, 0, 0], [1, 1, 0]), ([0, 0, 0], [1, 1, 1]), ([0, 0, 0], [1, 0, 1]), ([0, 0, 0], [0, 1, 1]), ([0, 0, 0], [0, 0, 1]), ([0, 0, 0], [0, 1, 0]), ([1, 0, 0], [0, 0, 0]), ([1, 0, 0], [1, 0, 0]), ([1, 0, 0], [1, 1, 0]), ([1, 0, 0], [1, 1, 1]), ([1, 0, 0], [1, 0, 1]), ([1, 0, 0], [0, 1, 1]), ([1, 0, 0], [0, 0, 1]), ([1, 0, 0], [0, 1, 0]), ([1, 1, 0], [0, 0, 0]), ([1, 1, 0], [1, 0, 0]), ([1, 1, 0], [1, 1, 0]), ([1, 1, 0], [1, 1, 1]), ([1, 1, 0], [1, 0, 1]), ([1, 1, 0], [0, 1, 1]), ([1, 1, 0], [0, 0, 1]), ([1, 1, 0], [0, 1, 0]), ([1, 1, 1], [0, 0, 0]), ([1, 1, 1], [1, 0, 0]), ([1, 1, 1], [1, 1, 0]), ([1, 1, 1], [1, 1, 1]), ([1, 1, 1], [1, 0, 1]), ([1, 1, 1], [0, 1, 1]), ([1, 1, 1], [0, 0, 1]), ([1, 1, 1], [0, 1, 0]), ([1, 0, 1], [0, 0, 0]), ([1, 0, 1], [1, 0, 0]), ([1, 0, 1], [1, 1, 0]), ([1, 0, 1], [1, 1, 1]), ([1, 0, 1], [1, 0, 1]), ([1, 0, 1], [0, 1, 1]), ([1, 0, 1], [0, 0, 1]), ([1, 0, 1], [0, 1, 0]), ([0, 1, 1], [0, 0, 0]), ([0, 1, 1], [1, 0, 0]), ([0, 1, 1], [1, 1, 0]), ([0, 1, 1], [1, 1, 1]), ([0, 1, 1], [1, 0, 1]), ([0, 1, 1], [0, 1, 1]), ([0, 1, 1], [0, 0, 1]), ([0, 1, 1], [0, 1, 0]), ([0, 0, 1], [0, 0, 0]), ([0, 0, 1], [1, 0, 0]), ([0, 0, 1], [1, 1, 0]), ([0, 0, 1], [1, 1, 1]), ([0, 0, 1], [1, 0, 1]), ([0, 0, 1], [0, 1, 1]), ([0, 0, 1], [0, 0, 1]), ([0, 0, 1], [0, 1, 0]), ([0, 1, 0], [0, 0, 0]), ([0, 1, 0], [1, 0, 0]), ([0, 1, 0], [1, 1, 0]), ([0, 1, 0], [1, 1, 1]), ([0, 1, 0], [1, 0, 1]), ([0, 1, 0], [0, 1, 1]), ([0, 1, 0], [0, 0, 1]), ([0, 1, 0], [0, 1, 0])]\n"
     ]
    }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Step 2:}$ Calculate the $\\Delta$ measure\n",
    "\n",
    "We calculate the Expected reciprocal rank of a ranking using the guy \n",
    "\n",
    "ERR := $\\sum_{r = 1}^n \\frac{1}{r}$ P(user stops at position r)\n",
    "\n",
    "where n is the number of documents in the ranking and\n",
    "\n",
    "$P = \\prod_{i=1}^{r-1} (1-R_i)R_r$\n",
    "\n",
    "where $R_i = \\frac{2^g - 1}{2^{g_{max}}}$ where $g_i$ is the grade of the i-th document and $g_{max}$ is the the maximum relevance.\n",
    "\n",
    "Putting it all together ERR:= $\\sum_{r = 1}^n \\frac{1}{r} \\prod_{i=1}^{r-1} (1-R_i)R_r$ \n",
    "\n",
    "As defined in the paper Expected Reciprocal Rank for Graded Relevance. Olivier Chapelle, Ya Zhang, Donald Meltzler, Pierre Grinspan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_ERR(ranking):\n",
    "    ''' This method calculates the ERR of a ranking. A ranking is a one dimensional interger list with length 3.\n",
    "    \n",
    "        @Input: a one dimensional list of length 3 with zeros and ones.\n",
    "        \n",
    "        @Output: a double (ERR score).\n",
    "    '''\n",
    "    ERR = 0\n",
    "    for r in range(len(ranking)):\n",
    "        prob_to_stop_at_r = ranking[r]/(r+1)\n",
    "        for i in range(r):\n",
    "            prob_to_stop_at_r *= 1 - ranking[i]\n",
    "            \n",
    "        ERR += prob_to_stop_at_r\n",
    "        \n",
    "    return ERR\n",
    "        \n",
    "calculate_ERR(rankings[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the $\\Delta $measures and split them in 10 buckets.\n",
    "\n",
    "The buckets are made such that group 1 contains all pairs for which 0.05 < $\\Delta$ measure ≤ 0.1, group 2 all pairs for which 0.1 < $\\Delta$measure ≤ 0.2, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def team_draft_interleaving(list_a, list_b):\n",
        "    ''' Team draft interleaving performed by throwing a coin. If its heads we put in the interleaved list\n",
        "        the first element of list A that is not already in,\n",
        "        if its tails we put in the interleaved list the first element of list B that is not already in.\n",
        "        \n",
        "        @Input: 2 lists of intergers of length 3.\n",
        "        \n",
        "        @Output: an interleaved list of tuples of length 3. Each tuple contain an integer (document ID) and a 0 or 1 \n",
        "        depending of which list it came from.\n",
        "    \n",
        "    '''\n",
        "\n",
        "    interleaved_list = []\n",
        "    counter = 0\n",
        "    while counter < 3:\n",
        "        coin_toss = random.random()\n",
        "\n",
        "        if(coin_toss > 0.5):\n",
        "            put_first_available_url_in_interleaved(list_a, 0, interleaved_list)\n",
        "            counter += 1\n",
        "            if(counter == 2):\n",
        "                return interleaved_list\n",
        "\n",
        "            put_first_available_url_in_interleaved(list_b, 1, interleaved_list)\n",
        "            counter += 1\n",
        "        else:\n",
        "            put_first_available_url_in_interleaved(list_b, 1, interleaved_list)\n",
        "            counter += 1\n",
        "            if(counter == 2):\n",
        "                return interleaved_list\n",
        "\n",
        "            put_first_available_url_in_interleaved(list_a, 0, interleaved_list)\n",
        "            counter += 1\n",
        "\n",
        "    return interleaved_list\n",
        "\n",
        "\n",
        "def put_first_available_url_in_interleaved(a_list, index_list, interleaved_list):\n",
        "    ''' Helper method that creates a tuple with and integer (document ID) and \n",
        "        a 0 or 1 which indicates from which list it came from and adds it in the interleaved list. \n",
        "        \n",
        "        @Input: - a list of intergers of length 3.\n",
        "                - a 0 or 1 indicator of the list.\n",
        "                - the interleaved list with all tuples of rnakings.\n",
        "         \n",
        "    '''\n",
        "    for i in a_list:\n",
        "        already_in_interleaved = False\n",
        "        for tupl in interleaved_list:\n",
        "            if tupl[0] == i:\n",
        "                already_in_interleaved = True\n",
        "\n",
        "        if i not already_in_interleaved:\n",
        "            tup = (i, index_list)\n",
        "            intearleaved_list.append(tup)\n",
        "            return\n"
      ],
      "outputs": [],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def probabilistic_interleaving(list_a, list_b):\n",
        "    ''' Probabilistic interleaving perfromed by throwing coins, if its heads we use the softmax function of list A\n",
        "        to choose randomly (with higher probability the more relevant rankings)\n",
        "        else we use the softmax function of list B. \n",
        "        After we put the choosen doc we remove it from both lists A and B softmaxes.\n",
        "        We do this until the interleaved list is full.\n",
        "        The interleaved list contains tuples with the document ID and a 0 or 1 considering the list that it came from.\n",
        "        \n",
        "        @Input: 2 lists of intergers of length 3.\n",
        "        \n",
        "        @Output: an interleaved list of tuples of length 3. Each tuple contain an integer (document ID) and a 0 or 1 \n",
        "        depending of which list it came from.\n",
        "    \n",
        "    '''\n",
        "    interleaved_list = []\n",
        "    counter = 0\n",
        "\n",
        "    while counter < 3:\n",
        "        coin_toss = random.random()\n",
        "\n",
        "        if(coin_toss > 0.5):\n",
        "            probs = softmax(list_a)\n",
        "            chosen = np.random.choice(list_a, probs)\n",
        "            list_a.remove(chosen)\n",
        "            list_b.remove(chosen)\n",
        "            counter += 1\n",
        "        else:\n",
        "            probs = softmax(list_b)\n",
        "            chosen = np.random.choice(list_b, probs)\n",
        "            list_b.remove(chosen)\n",
        "            list_a.remove(chosen)\n",
        "            counter += 1\n",
        "\n",
        "    return interleaved_list\n",
        "\n",
        "\n",
        "def softmax(rankings, tau=3):\n",
        "    ''' Helper method that calculates the probabilities of every document in the given list\n",
        "        using the softmax function in a vectorised from.\n",
        "        \n",
        "        @Input: list of intergers of length 3 (rankings).\n",
        "        \n",
        "        @Output: a vector with probabilities for every document.\n",
        "    \n",
        "    '''\n",
        "    numerators = 1 / np.power(rankings, tau)\n",
        "    denominator = numerators.sum()\n",
        "\n",
        "    return numerators / denominator\n"
      ],
      "outputs": [],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %%\n",
        "import re\n",
        "\n",
        "CUTOFF = 3\n",
        "class YandexData():\n",
        "    \"\"\"\n",
        "    take the path to YandexData, load all needed entries.\n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"\n",
        "        The structure of lookup table:\n",
        "        {\n",
        "            'q_id':{\n",
        "                'sessions':[\n",
        "                {\n",
        "                    'url_ids':[],\n",
        "                    'clicks':[]\n",
        "                }\n",
        "                ]\n",
        "                'docs':set([])\n",
        "            }\n",
        "        }\n",
        "        `q_id` is the id of the different queries\n",
        "        `session` is a list of the sessions of this particular `q_id`\n",
        "        each `session` have a list of `url_ids` and a `clicks` list, the url in `clicks` must be in the `url_ids`\n",
        "        `docs` is the union of all urls returned by the system per query\n",
        "        \"\"\"\n",
        "        queries_lookup = {}\n",
        "        new_item = lambda: {'sessions': [], 'docs': set()}\n",
        "        turn2int = lambda x: [int(i) for i in x]\n",
        "        # state='Q'\n",
        "        with open(self.path, 'r') as f:\n",
        "            click = []\n",
        "            last_q = None\n",
        "            for line in f.readlines():\n",
        "                vals = re.split(r'\\t+', line.rstrip())\n",
        "                if vals[2] == 'Q':\n",
        "                    # state = 'Q'\n",
        "                    pres_q = vals[3]\n",
        "                    # we only care about the first CUTOFF urls\n",
        "                    cutoff_urls = turn2int(vals[5:5 + CUTOFF])\n",
        "                    if pres_q not in queries_lookup.keys():\n",
        "                        it = new_item()\n",
        "                    else:\n",
        "                        it = queries_lookup[pres_q]\n",
        "                    it['docs'] = it['docs'].union(cutoff_urls)\n",
        "                    it['sessions'].append({'urls': cutoff_urls, 'clicks': []})\n",
        "                    queries_lookup[pres_q] = it\n",
        "                    last_q = pres_q\n",
        "                elif vals[2] == 'C':\n",
        "                    if int(vals[3]) in queries_lookup[last_q]['sessions'][-1]['urls']:\n",
        "                        queries_lookup[last_q][\n",
        "                            'sessions'][-1]['clicks'].append(int(vals[3]))\n",
        "                    # state = 'C'\n",
        "        self.queries_lookup = queries_lookup\n",
        "        return"
      ],
      "outputs": [],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random as rd\n",
        "\n",
        "class ClickModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def train(self, data):\n",
        "        raise NotImplementedError\n",
        "    def get_probs(self, rankings):\n",
        "        raise NotImplementedError\n",
        "    def is_click(self, rankings, epsilon):\n",
        "        \"\"\"\n",
        "        simulate the click, return a boolean list of the same length as `rankings`, True means clicked\n",
        "        \"\"\"\n",
        "        probs = self.get_probs(rankings, epsilon)\n",
        "        click_fn = lambda p: rd.uniform(0, 1) < p\n",
        "        return list(map(click_fn, probs))"
      ],
      "outputs": [],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class RCM(ClickModel):\n",
        "    \"\"\"\n",
        "        Random clicking model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gamma = [0] * 3\n",
        "\n",
        "    def train(self, data, load=True):\n",
        "        \"\"\"\n",
        "            get the \\rho paramter for random clicking by calculating the fraction of clicked urls among all returned results\n",
        "        \"\"\"\n",
        "        if load:\n",
        "            self.rho = 0.2802838475726031\n",
        "            return\n",
        "        sess_num = 0\n",
        "        cli_num = 0\n",
        "        for q, it in data.queries_lookup.items():\n",
        "            for sess in it['sessions']:\n",
        "                cli_num += len(sess['clicks'])\n",
        "            sess_num += len(it['sessions'])\n",
        "        self.rho = cli_num / sess_num / CUTOFF\n",
        "        return\n",
        "\n",
        "    def get_probs(self, rankings, epsilon=None):\n",
        "        \"\"\"\n",
        "            return \\rho list regardless\n",
        "        \"\"\"\n",
        "        return [self.rho] * len(rankings)\n"
      ],
      "outputs": [],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "class PBM(ClickModel):\n",
        "    \"\"\"\n",
        "        Position based clicking model\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.alpha_uq = {}\n",
        "        self.gamma_r = [rd.uniform(0, 1) for _ in range(CUTOFF)]\n",
        "\n",
        "    def train(self, data, T=20, load=False):\n",
        "        \"\"\"\n",
        "            train the parameter according to data\n",
        "            data: yandex data\n",
        "            T: time steps of the training loop\n",
        "            load: whether use the trained gamma(we dont need trained alpha because during inference they are replaced by epsilon)\n",
        "        \"\"\"\n",
        "        if load:\n",
        "            self.gamma_r = [0.9998564405092062,\n",
        "                            0.48278049975990095, 0.3335993103977007]\n",
        "            return\n",
        "        self._init_alpha(data)\n",
        "        for _ in range(T):\n",
        "            self._update_alpha(data)\n",
        "            self._update_gamma(data)\n",
        "\n",
        "    def _init_alpha(self, data):\n",
        "        \"\"\"\n",
        "        init the alpha to be a dict where only the present (query, doc) pairs have value\n",
        "        \"\"\"\n",
        "        for q, it in data.queries_lookup.items():\n",
        "            for doc in it['docs']:\n",
        "                self.alpha_uq[(q, doc)] = rd.uniform(0, 1)\n",
        "\n",
        "    def _update_alpha(self, data):\n",
        "        \"\"\"\n",
        "        data is the yandex data.\n",
        "        This function performs an update of alpha in EM\n",
        "        \"\"\"\n",
        "\n",
        "        ql = data.queries_lookup\n",
        "        new_alpha_uq = deepcopy(self.alpha_uq)\n",
        "        for (q, u), alpha in self.alpha_uq.items():\n",
        "            count = 2\n",
        "            contribution_sum = 1\n",
        "            for sess in ql[q]['sessions']:\n",
        "                if u not in sess['urls']:\n",
        "                    continue\n",
        "                count += 1\n",
        "                if u in sess['clicks']:\n",
        "                    contribution_sum += 1\n",
        "                else:\n",
        "                    ind = sess['urls'].index(u)\n",
        "                    contribution_sum += (1 - self.gamma_r[ind]) * \\\n",
        "                        alpha / (1 - self.gamma_r[ind] * alpha)\n",
        "            new_alpha_uq[(q, u)] = contribution_sum / count\n",
        "        self.alpha_uq = new_alpha_uq\n",
        "        return\n",
        "\n",
        "    def _update_gamma(self, data):\n",
        "        \"\"\"\n",
        "        data is the yandex data.\n",
        "        This function performs an update of gamma in EM\n",
        "        \"\"\"\n",
        "\n",
        "        ql = data.queries_lookup\n",
        "        sess_num = 0\n",
        "        contrib_sum = [0] * CUTOFF\n",
        "        for q, item in ql.items():\n",
        "            sess_num += len(item['sessions'])\n",
        "            for sess in item['sessions']:\n",
        "                for i, u in enumerate(sess['urls']):\n",
        "                    if u in sess['clicks']:\n",
        "                        contrib_sum[i] += 1\n",
        "                    else:\n",
        "                        contrib_sum[i] += self.gamma_r[i] * (1 - self.alpha_uq[q, u]) / (\n",
        "                            1 - self.gamma_r[i] * self.alpha_uq[q, u])\n",
        "\n",
        "        self.gamma_r = [i / sess_num for i in contrib_sum]\n",
        "        return\n",
        "\n",
        "    def get_probs(self, rankings, epsilon):\n",
        "        \"\"\"\n",
        "            assume `rankings` are list of relevance labels\n",
        "            use `epsilon` to substitute alpha, typical value is 0.1\n",
        "        \"\"\"\n",
        "        prob_fn = lambda args: self.gamma_r[\n",
        "            args[0]] * (1 - epsilon if args[1] == 1 else epsilon)\n",
        "        return list(map(prob_fn, enumerate(rankings)))\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {},
      "execution_count": null
    }
   ],
   "source": [
    "def calculate_Dmeasures(rankings):\n",
    "    ''' This method calculates the difference in ERR between the two rankings of every tuple, \n",
    "        for all tuples of rankings.\n",
    "        Since we need to store the results in 10 different buckets we use a dictionary with keys 10 integers \n",
    "        from 0 to 9 with step 1 and values the list of our measurements.\n",
    "    \n",
    "        @Input: a list of tuples.\n",
    "        \n",
    "        @Output: A dictionary with keys integers from 0 to 9 and values 10 lists of doubles. \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    measures = {k:[] for k in range(10)}\n",
    "    for index, r in enumerate(rankings):\n",
    "        ERR_P = calculate_ERR(r[0])\n",
    "        ERR_E = calculate_ERR(r[1])\n",
    "        \n",
    "        d_measure = ERR_E - ERR_P\n",
    "        \n",
    "        if d_measure >= 0.05 and d_measure <= 0.95:\n",
    "            measures[int(d_measure * 10)].append(index)\n",
    "            \n",
    "    \n",
    "    return measures\n",
    "\n",
    "measures = calculate_Dmeasures(rankings)\n",
    "print(measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Step 3}$: Implement Team-Draft Interleaving and Probabilistic Intearleaving\n",
    "\n",
    "$\\textbf{Team Draft Interleaving}$ is performed by throwing a coin. If its heads we put, in the interleaved list,\n",
    "the first document of list A that is not already in and then the first document of list B that is not already in,\n",
    "if its tails we start with B and then A.\n",
    "We repeat until the interleaved list if full.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_draft_interleaving(list_a, list_b):\n",
    "    ''' Team draft interleaving is performed by throwing a coin. If its heads we put in the interleaved list\n",
    "        the first element of list A that is not already in,\n",
    "        if its tails we put in the interleaved list the first element of list B that is not already in.\n",
    "        \n",
    "        @Input: 2 lists of intergers of length 3.\n",
    "        \n",
    "        @Output: an interleaved list of tuples of length 3. Each tuple contain an integer (document ID) and a 0 or 1 \n",
    "        depending of which list it came from.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    interleaved_list = [ ]\n",
    "    counter = 0\n",
    "    while counter < 3:\n",
    "        coin_toss = random.random()\n",
    "                   \n",
    "        if(coin_toss > 0.5):\n",
    "            put_first_available_url_in_interleaved(list_a, 0, interleaved_list)\n",
    "            counter += 1\n",
    "            if(counter == 2):\n",
    "                return interleaved_list\n",
    "            \n",
    "            put_first_available_url_in_interleaved(list_b, 1, interleaved_list)  \n",
    "            counter += 1\n",
    "        else:\n",
    "            put_first_available_url_in_interleaved(list_b, 1, interleaved_list)\n",
    "            counter += 1\n",
    "            if(counter == 2):\n",
    "                return interleaved_list\n",
    "            \n",
    "            put_first_available_url_in_interleaved(list_a, 0, interleaved_list)\n",
    "            counter += 1\n",
    "            \n",
    "    return interleaved_list\n",
    "\n",
    "    \n",
    "def put_first_available_url_in_interleaved(a_list, index_list, interleaved_list):\n",
    "    ''' Helper method that creates a tuple with and integer (document ID) and \n",
    "        a 0 or 1 which indicates from which list it came from and adds it in the interleaved list. \n",
    "        \n",
    "        @Input: - a list of intergers of length 3.\n",
    "                - a 0 or 1 indicator of the list.\n",
    "                - the interleaved list with all tuples of rnakings.\n",
    "         \n",
    "    '''\n",
    "    for i in a_list:\n",
    "        already_in_interleaved = False\n",
    "        for tupl in interleaved_list:\n",
    "            if tupl[0] == i:\n",
    "                already_in_interleaved = True\n",
    "                \n",
    "        if i not already_in_interleaved:\n",
    "            tup = (i, index_list)\n",
    "            intearleaved_list.append(tup)\n",
    "            return\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Probabilistic Intearleaving}$ is performed similarly but instead of choosing the first document we chose the documents from the lists probabilisticly where the probabilities of the documents are produced from 2 softmax functions\n",
    "(one for every list).\n",
    "\n",
    "The softmax function assigns probability of selecting a document ($P_{s_{x}}(d)$) that is inversely proportional to a power of the rank $r_x(d)$ of a document d in a list.\n",
    "\n",
    "$P_{s_{x}}(d) = \\frac{ \\frac{1}{r_x(d)^\\tau}}{\\sum_{d2\\in D} \\frac{1}{r_x(d2)^\\tau}}$ \n",
    "\n",
    "where the parameter $\\tau$ controls how quickly selection probabilities decay as rank decreases.\n",
    "\n",
    "as defined in the paper A Probabilistic Method for Inferring Preferences from Clicks. Katja Hofmann, Shimon Whiteson and Maarten de Rijke. University of Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def probabilistic_interleaving(list_a, list_b):\n",
    "    ''' Probabilistic interleaving perfromed by throwing coins, if its heads we use the softmax function of list A\n",
    "        to choose randomly (with higher probability the more relevant rankings)\n",
    "        else we use the softmax function of list B. \n",
    "        After we put the choosen doc we remove it from both lists A and B softmaxes.\n",
    "        We do this until the interleaved list is full.\n",
    "        The interleaved list contains tuples with the document ID and a 0 or 1 considering the list that it came from.\n",
    "        \n",
    "        @Input: 2 lists of intergers of length 3.\n",
    "        \n",
    "        @Output: an interleaved list of tuples of length 3. Each tuple contain an integer (document ID) and a 0 or 1 \n",
    "        depending of which list it came from.\n",
    "    \n",
    "    '''\n",
    "    interleaved_list = [ ]\n",
    "    counter = 0\n",
    "    \n",
    "    while counter < 3:\n",
    "        coin_toss = random.random()\n",
    "                   \n",
    "        if(coin_toss > 0.5):\n",
    "            probs = softmax(list_a)\n",
    "            chosen = np.random.choice(list_a, probs)\n",
    "            list_a.remove(chosen)\n",
    "            list_b.remove(chosen)\n",
    "            counter += 1\n",
    "        else:\n",
    "            probs = softmax(list_b)\n",
    "            chosen = np.random.choice(list_b, probs)\n",
    "            list_b.remove(chosen)\n",
    "            list_a.remove(chosen)\n",
    "            counter += 1\n",
    "           \n",
    "            \n",
    "    return interleaved_list\n",
    "    \n",
    "    \n",
    "def softmax(rankings, tau = 3):\n",
    "    ''' Helper method that calculates the probabilities of every document in the given list\n",
    "        using the softmax function in a vectorised from.\n",
    "        \n",
    "        @Input: list of intergers of length 3 (rankings).\n",
    "        \n",
    "        @Output: a vector with probabilities for every document.\n",
    "    \n",
    "    '''\n",
    "    numerators = 1 / np.power(rankings, tau)\n",
    "    denominator = numerators.sum()\n",
    "    \n",
    "    return numerators / denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
