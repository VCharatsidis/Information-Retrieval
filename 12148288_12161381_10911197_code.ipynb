{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "version": "3.6.1",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "nbconvert_exporter": "python",
      "file_extension": ".py",
      "name": "python"
    },
    "anaconda-cloud": {}
  },
  "cells": [
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "\n",
        "import numpy as np\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "\n",
        "def simulate_rankings():\n",
        "    P = [[0, 0, 0], [1, 0, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [0, 1, 1], [0, 0, 1], [0, 1, 0]]\n",
        "    E = [[0, 0, 0], [1, 0, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [0, 1, 1], [0, 0, 1], [0, 1, 0]]\n",
        "    rankings = []\n",
        "    for p in P:\n",
        "        for e in E:\n",
        "            tup1 = (p, e)\n",
        "            rankings.append(tup1)\n",
        "    \n",
        "    print(rankings)\n",
        "    return rankings\n",
        "    \n",
        "rankings = simulate_rankings()"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "def calculate_ERR(ranking):\n",
        "    ERR = 0\n",
        "    for r in range(len(ranking)):\n",
        "        prob_to_stop_at_r = ranking[r]/(r+1)\n",
        "        for i in range(r):\n",
        "            prob_to_stop_at_r *= 1 - ranking[i]\n",
        "            \n",
        "        ERR += prob_to_stop_at_r\n",
        "        \n",
        "    return ERR\n",
        "        \n",
        "calculate_ERR(rankings[1][1])"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "def calculate_Dmeasures(rankings):\n",
        "    \n",
        "    measures = {k:[] for k in range(10)}\n",
        "    for index, r in enumerate(rankings):\n",
        "        ERR_P = calculate_ERR(r[0])\n",
        "        ERR_E = calculate_ERR(r[1])\n",
        "        \n",
        "        d_measure = ERR_E - ERR_P\n",
        "        \n",
        "        if d_measure >= 0.05 and d_measure <= 0.95:\n",
        "            measures[int(d_measure * 10)].append(index)\n",
        "            \n",
        "    \n",
        "    return measures\n",
        "\n",
        "measures = calculate_Dmeasures(rankings)\n",
        "print(measures)"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "def team_draft_interleaving(list_a, list_b):\n",
        "    \n",
        "    interleaved_list = [ ]\n",
        "    counter = 0\n",
        "    while counter < 3:\n",
        "        coin_toss = random.random()\n",
        "                   \n",
        "        if(coin_toss > 0.5):\n",
        "            put_first_available_url_in_interleaved(list_a, 0, interleaved_list)\n",
        "            counter += 1\n",
        "            if(counter == 2):\n",
        "                return interleaved_list\n",
        "            \n",
        "            put_first_available_url_in_interleaved(list_b, 1, interleaved_list)  \n",
        "            counter += 1\n",
        "        else:\n",
        "            put_first_available_url_in_interleaved(list_b, 1, interleaved_list)\n",
        "            counter += 1\n",
        "            if(counter == 2):\n",
        "                return interleaved_list\n",
        "            \n",
        "            put_first_available_url_in_interleaved(list_a, 0, interleaved_list)\n",
        "            counter += 1\n",
        "            \n",
        "    return interleaved_list\n",
        "\n",
        "    \n",
        "def put_first_available_url_in_interleaved(a_list, index_list, interleaved_list):\n",
        "    for i in a_list:\n",
        "        if i not in interleaved_list:\n",
        "            tup = (i, index_list)\n",
        "            intearleaved_list.append(tup)\n",
        "            return\n",
        "  \n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "def probabilistic_interleaving(list_a, list_b):\n",
        "    interleaved_list = [ ]\n",
        "    counter = 0\n",
        "    \n",
        "    while counter < 3:\n",
        "        coin_toss = random.random()\n",
        "                   \n",
        "        if(coin_toss > 0.5):\n",
        "            probs = softmax(list_a)\n",
        "            chosen = np.random.choice(list_a, probs)\n",
        "            list_a.remove(chosen)\n",
        "            list_b.remove(chosen)\n",
        "            counter += 1\n",
        "        else:\n",
        "            probs = softmax(list_b)\n",
        "            chosen = np.random.choice(list_b, probs)\n",
        "            list_b.remove(chosen)\n",
        "            list_a.remove(chosen)\n",
        "            counter += 1\n",
        "           \n",
        "            \n",
        "    return interleaved_list\n",
        "    \n",
        "    \n",
        "def softmax(rankings, tau = 3):\n",
        "    numerators = 1 / np.power(rankings, tau)\n",
        "    denominator = numerators.sum()\n",
        "    \n",
        "    return numerators / denominator\n",
        "    "
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "import re\n",
        "\n",
        "CUTOFF = 3\n",
        "class YandexData():\n",
        "    \"\"\"\n",
        "    take the path to YandexData, load all needed entries.\n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"\n",
        "        The structure of lookup table:\n",
        "        {\n",
        "            'q_id':{\n",
        "                'sessions':[\n",
        "                {\n",
        "                    'url_ids':[],\n",
        "                    'clicks':[]\n",
        "                }\n",
        "                ]\n",
        "                'docs':set([])\n",
        "            }\n",
        "        }\n",
        "        `q_id` is the id of the different queries\n",
        "        `session` is a list of the sessions of this particular `q_id`\n",
        "        each `session` have a list of `url_ids` and a `clicks` list, the url in `clicks` must be in the `url_ids`\n",
        "        `docs` is the union of all urls returned by the system per query\n",
        "        \"\"\"\n",
        "        queries_lookup = {}\n",
        "        new_item = lambda: {'sessions': [], 'docs': set()}\n",
        "        turn2int = lambda x: [int(i) for i in x]\n",
        "        # state='Q'\n",
        "        with open(self.path, 'r') as f:\n",
        "            click = []\n",
        "            last_q = None\n",
        "            for line in f.readlines():\n",
        "                vals = re.split(r'\\t+', line.rstrip())\n",
        "                if vals[2] == 'Q':\n",
        "                    # state = 'Q'\n",
        "                    pres_q = vals[3]\n",
        "                    # we only care about the first CUTOFF urls\n",
        "                    cutoff_urls = turn2int(vals[5:5 + CUTOFF])\n",
        "                    if pres_q not in queries_lookup.keys():\n",
        "                        it = new_item()\n",
        "                    else:\n",
        "                        it = queries_lookup[pres_q]\n",
        "                    it['docs'] = it['docs'].union(cutoff_urls)\n",
        "                    it['sessions'].append({'urls': cutoff_urls, 'clicks': []})\n",
        "                    queries_lookup[pres_q] = it\n",
        "                    last_q = pres_q\n",
        "                elif vals[2] == 'C':\n",
        "                    if int(vals[3]) in queries_lookup[last_q]['sessions'][-1]['urls']:\n",
        "                        queries_lookup[last_q][\n",
        "                            'sessions'][-1]['clicks'].append(int(vals[3]))\n",
        "                    # state = 'C'\n",
        "        self.queries_lookup = queries_lookup\n",
        "        return"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "source": [
        "import random as rd\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "class PBM(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.alpha_uq = {}\n",
        "        self.gamma_r = [rd.uniform(0, 1) for _ in range(CUTOFF)]\n",
        "\n",
        "    def train(self, data, T=20, load=False):\n",
        "        \"\"\"\n",
        "            train the parameter according to data\n",
        "            data: yandex data\n",
        "            T: time steps of the training loop\n",
        "            load: whether use the trained gamma(we dont need trained alpha because during inference they are replaced by epsilon)\n",
        "        \"\"\"\n",
        "        if load:\n",
        "            self.gamma_r = [0.9998564405092062,\n",
        "                            0.48278049975990095, 0.3335993103977007]\n",
        "            return\n",
        "        self._init_alpha(data)\n",
        "        for _ in range(T):\n",
        "            self._update_alpha(data)\n",
        "            self._update_gamma(data)\n",
        "\n",
        "    def _init_alpha(self, data):\n",
        "        \"\"\"\n",
        "        init the alpha to be a dict where only the present (query, doc) pairs have value\n",
        "        \"\"\"\n",
        "        for q, it in data.queries_lookup.items():\n",
        "            for doc in it['docs']:\n",
        "                self.alpha_uq[(q, doc)] = rd.uniform(0, 1)\n",
        "\n",
        "    def _update_alpha(self, data):\n",
        "        \"\"\"\n",
        "        data is the yandex data.\n",
        "        This function performs an update of alpha in EM\n",
        "        \"\"\"\n",
        "\n",
        "        ql = data.queries_lookup\n",
        "        new_alpha_uq = deepcopy(self.alpha_uq)\n",
        "        for (q, u), alpha in self.alpha_uq.items():\n",
        "            count = 2\n",
        "            contribution_sum = 1\n",
        "            for sess in ql[q]['sessions']:\n",
        "                if u not in sess['urls']:\n",
        "                    continue\n",
        "                count += 1\n",
        "                if u in sess['clicks']:\n",
        "                    contribution_sum += 1\n",
        "                else:\n",
        "                    ind = sess['urls'].index(u)\n",
        "                    contribution_sum += (1 - self.gamma_r[ind]) * \\\n",
        "                        alpha / (1 - self.gamma_r[ind] * alpha)\n",
        "            new_alpha_uq[(q, u)] = contribution_sum / count\n",
        "        self.alpha_uq = new_alpha_uq\n",
        "        return\n",
        "\n",
        "    def _update_gamma(self, data):\n",
        "        \"\"\"\n",
        "        data is the yandex data.\n",
        "        This function performs an update of gamma in EM\n",
        "        \"\"\"\n",
        "\n",
        "        ql = data.queries_lookup\n",
        "        sess_num = 0\n",
        "        contrib_sum = [0] * CUTOFF\n",
        "        for q, item in ql.items():\n",
        "            sess_num += len(item['sessions'])\n",
        "            for sess in item['sessions']:\n",
        "                for i, u in enumerate(sess['urls']):\n",
        "                    if u in sess['clicks']:\n",
        "                        contrib_sum[i] += 1\n",
        "                    else:\n",
        "                        contrib_sum[i] += self.gamma_r[i] * (1 - self.alpha_uq[q, u]) / (\n",
        "                            1 - self.gamma_r[i] * self.alpha_uq[q, u])\n",
        "\n",
        "        self.gamma_r = [i / sess_num for i in contrib_sum]\n",
        "        return\n",
        "\n",
        "    def get_probs(self, rankings, epsilon):\n",
        "        \"\"\"\n",
        "            assume `rankings` are list of relevance labels\n",
        "            use `epsilon` to substitute alpha, typical value is 0.1\n",
        "        \"\"\"\n",
        "        prob_fn = lambda args: self.gamma_r[\n",
        "            args[0]] * (1 - epsilon if args[1] == 1 else epsilon)\n",
        "        return list(map(prob_fn, enumerate(rankings)))\n",
        "\n",
        "    def is_click(self, rankings, epsilon):\n",
        "        \"\"\"\n",
        "        simulate the click, return a boolean list of the same length as `rankings`, True means clicked\n",
        "        \"\"\"\n",
        "        probs = self.get_probs(rankings, epsilon)\n",
        "        click_fn = lambda p: rd.uniform(0, 1) < p\n",
        "        return list(map(click_fn, probs))\n"
      ]
    }
  ],
  "nbformat_minor": 1,
  "nbformat": 4
}
